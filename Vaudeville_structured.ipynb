{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e3073172",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Vaudeville: Generating Structured Data of Musical Moments\"\n",
    "author: 'Charlie Cross'\n",
    "date: 'July 10, 2025'\n",
    "\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "    embed-resources: true\n",
    "plotly-connected: true\n",
    "jupyter: python3\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909dff3",
   "metadata": {},
   "source": [
    "# Vaudeville: Structured Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7abe89",
   "metadata": {},
   "source": [
    "I give a lot more detail about Structured Output in the tutorial on github. There are, however, some brief descriptions about what each block of code does here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daeef9d",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "In this notebook, we want to set up a framework to extract a list of Musical Moments from a given Vaudeville play. To do this, we: \n",
    "\n",
    "* Set up a Pydantic Basemodel defining the aspects of a Musical Moment.\n",
    "* Set up a Basemodel for a whole play (or scene) that we pass it, containing a list of Musical Moments.\n",
    "* Bind an LLM to this structured output\n",
    "* Split the play up into scenes, to have the LLM analyze one at a time\n",
    "    * With too much content at once, it begins to yield lower accuracy results\n",
    "* Feed each scene into the LLM, and group it back together into one object\n",
    "* Convert and export the final object, containing an entire play, as a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0122a66d",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "## Full Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68705084",
   "metadata": {},
   "source": [
    "Below, we have grouped the full workflow into one large sequence. Thus, you can change the pdf_filepath variable, hit run all below, and a csv will be exported into your directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6477fe23",
   "metadata": {},
   "source": [
    "### Loading the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e7f5c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hit execute cells below once you add your pdf_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df4de89",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "  background:#00e676;           /* bright green */\n",
    "  color:#111;                   /* dark text for strong contrast */\n",
    "  padding:14px 18px;\n",
    "  border-left:6px solid #00C853;/* slightly darker green accent */\n",
    "  border-radius:10px;\n",
    "  font-weight:600;\n",
    "  line-height:1.4;\n",
    "\">\n",
    "  Once you're ready to process a PDF, upload your PDF then change the filepath below. Create a folder in your workspace called `csv_outputs`. Then restart your kernel and run all. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3585d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_filepath = \"Files/PDFs/Scribe-Cornu_-_La_chanoinesse.pdf\" \n",
    "# Place your PDF filepath here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed204a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is what your output will be named later\n",
    "csv_filename = pdf_filepath.replace(\"Files/PDFs/\",\"\").replace(\".pdf\",\".csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05edd42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up pdf loading\n",
    "\n",
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import PDFPlumberLoader\n",
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict, Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "async def loadPDF(filepath: str) -> list:\n",
    "    loader = PyPDFLoader(filepath)\n",
    "    pages = []\n",
    "    async for page in loader.alazy_load():\n",
    "        pages.append(page)   \n",
    "    return pages\n",
    "\n",
    "# filepath:str = input(\"Please enter the filepath: \")\n",
    "source = await loadPDF(pdf_filepath)\n",
    "\n",
    "for page in source:\n",
    "        page.metadata['source'] = page.metadata['source'].replace(\"Files\\PDFs\\\\\",\"\")\n",
    "\n",
    "source_content = \"\"\n",
    "for page in source:\n",
    "    source_content += page.page_content\n",
    "source_full = Document(page_content = source_content, metadata = source[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5107d458",
   "metadata": {},
   "source": [
    "### Splitting up the PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd56ed17",
   "metadata": {},
   "source": [
    "Here, we have the LLM return the scene headers as they appear in the text. Then, we split on these headers.\n",
    "\n",
    "This is not perfect and a few headers are always missed, but it works well enough to split up the text into manageable chunks for the app. It also guarantees a split cannot occur in the middle of a scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b8e3962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "processing_llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6783a71c",
   "metadata": {},
   "source": [
    "The \"Description\" field is what the LLM uses to find each variable within a scene. For each variable, we want to tell it *what it is*, and *where to find it*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b49ec5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Scene(BaseModel):\n",
    "    \"\"\"A single scene from a Vaudeville play\"\"\"\n",
    "\n",
    "    act: int = Field(description=\"The act number or label as it appears in the text.\")\n",
    "    scene: int = Field(description=\"The scene number or label as it appears in the text.\")\n",
    "    header: str = Field(description=\"The exact scene header line, copied verbatim from the text.\")\n",
    "\n",
    "class FullPlay(BaseModel):\n",
    "    \"\"\"A full play, that has yet to be broken into individual scenes.\"\"\"\n",
    "\n",
    "    all_scenes: List[Scene] = Field(description=\"A list of every single scene's header and label - each as a Scene object.\")\n",
    "\n",
    "formatted_splitter_llm = processing_llm.with_structured_output(FullPlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca95916",
   "metadata": {},
   "source": [
    "Here, we're setting up our first LLM \"node\" in our app. This node returns the headers of scenes so that we can split it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "859dc8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "The following is the full text of a French Vaudeville play. Your job is to identify every scene boundary.\n",
    "For each scene, return:\n",
    "- The act number (as it appears in the text)\n",
    "- The scene number (as it appears in the text)\n",
    "- The exact scene header line (copy it verbatim from the text)\n",
    "\n",
    "Return a list of objects like:\n",
    "{{\"act\": \"...\", \"scene\": \"...\", \"header\": \"...\"}}\n",
    "\n",
    "Do not attempt to count character indexes. Only return the scene headers as they appear in the text.\n",
    "\n",
    "Play Content: \\n\n",
    "{source_full.page_content}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d88eba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_up_play(doc):\n",
    "    response = formatted_splitter_llm.invoke(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fd0f744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indexes = split_up_play(source_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7b84a2",
   "metadata": {},
   "source": [
    "This is pretty complex code, so don't worry if you can't figure it out. In essence, it's finding the scenes titles that the LLM provided and splitting on them, returning a list of scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "efbfe648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "all_splits = []\n",
    "scene_headers = all_indexes.all_scenes\n",
    "full_text = source_full.page_content\n",
    "\n",
    "prev_end_idx = 0\n",
    "for i, scene in enumerate(scene_headers):\n",
    "    # Find the start index of this scene's header after the previous end index\n",
    "    start_idx = full_text.find(scene.header, prev_end_idx)\n",
    "    if start_idx == -1:\n",
    "        print(f\"Scene header not found: {scene.header}\")\n",
    "\n",
    "    # Determine the end index: start of next scene header, or end of document\n",
    "    if i + 1 < len(scene_headers):\n",
    "        next_start_idx = full_text.find(scene_headers[i + 1].header, start_idx + len(scene.header))\n",
    "        if next_start_idx == -1:\n",
    "            end_idx = len(full_text)\n",
    "        else:\n",
    "            end_idx = next_start_idx\n",
    "    else:\n",
    "        end_idx = len(full_text)\n",
    "\n",
    "    scene_text = full_text[start_idx:end_idx]\n",
    "    doc = Document(page_content=scene_text, metadata={\"act\": scene.act, \"scene\": scene.scene, \"header\": scene.header})\n",
    "    all_splits.append(doc)\n",
    "    prev_end_idx = end_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e8c2fb",
   "metadata": {},
   "source": [
    "### Setting up the pydantic object and LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebf549d",
   "metadata": {},
   "source": [
    "This is where we define what the want back. This is usually the first thing you'll do. As you can see, we're asking it to find a whole lot of things within the MusicalMoment: characters, rhyme scheme, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7a99e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Pydantic\n",
    "class MusicalMoment(BaseModel):\n",
    "    \"\"\"Many of these musical moments reuse some preexisting (and often well-known)  melody or tune.  These are variously called \"melodie”, or “air”, and identified with a short title that refers in some way to an opera or collection of melodies from which it was drawn.  The titles might include the names of works, or other characters in those original works. In the context of the plays, these tunes become the vehicle for newly composed lyrics, which are normally rhymed, and which normally follow the poetic scansion and structure of the original lyrics.  Rhyme, versification and structure are thus of interest to us.\"\"\"\n",
    "\n",
    "    act: int = Field(description=\"The act number in which this musical moment takes place. Will be labeled at the top of the act or scene in which it takes place.\")\n",
    "    scene: int = Field(description=\"The scene number in which the musical moment takes place. Will be labeled at the top of the scene.\")\n",
    "    number: int = Field(description = \"The index of the musical moment in the scene. For example, if this is the first musical moment in the scene, this should be 1.\")\n",
    "    characters: list[str] = Field(description=\"the character or characters who are singing (or otherwise making music) within this specific musical moment,\")\n",
    "    dramatic_situation: str = Field(description=\"the dramatic situation (a love scene, a crowd scene) in which the musical moment is occurring\")\n",
    "    air_or_melodie: str = Field(description=\"The title of the 'air' or 'melodie' of which the musical moment is based. It will be labeled in the text as 'air' or 'melodie'.\")\n",
    "    poetic_text: str = Field(description=\"The text from the music number. Do not include stage directions, only the lyrics sung by the characters in this musical moment\")\n",
    "    rhyme_scheme: str = Field(description = \"The rhyme scheme for the poetic text in the musical moment. For example, sentences that end in 'tree' 'be' 'why' and 'high' would have a rhyme scheme of AABB.\")\n",
    "    poetic_form: str = Field(description=\"form of the poetic text, which might involve some refrain\")\n",
    "    end_of_line_accents: list[str] = Field(description = \"the end accent for each line (masculine or féminine)\")\n",
    "    syllable_count_per_line: list[int] = Field(description = \"the number of syllables per line. look out for contractions and colloquialisms.that might make the count of syllables less than obvious. Normally a word like ‘voilà’ would of course have 2 syllables. But the musical rhythm of a particular melodie might require that it be _sung_ as only one syllable, as would be the case if the text reads ‘v’la’. Similarly ‘mademoiselle’ would have 4 syllables in spoken French. But the musical context might make it sound like 5. Or a character speaking dialect might sing “Mam’zelle”, which would have only 2 (or perhaps 3) syllables.\")\n",
    "    irregularities: Optional[str] = Field(description=\"any irregularities within the musical number\")\n",
    "    stage_direction_or_cues: Optional[str] = Field(description=\"any stage directions, which tell a character what to do, but aren't a part of another character's dialogue. These are usually connected with a character’s name, and often are in some contrasting typography (italics, or in parentheses - though this may not be picked up by the filereader).  Sometimes these directions even happen in the midst of a song! In a related way there are sometimes ‘cues’ for music, or performance (as when there is an offstage sound effect, or someone is humming) Most times the stage directions appear just before or after the song text. But sometimes they appear in the midst of the texts. The directions should be reported here and not in the transcription of the poem.\")\n",
    "    reprise: Optional[str] = Field(description=\"there are sometimes directions that indicate the ‘reprise’ of some earlier number or chorus.\")\n",
    "\n",
    "class VaudevillePlay(BaseModel):\n",
    "    musicalMoments: list[MusicalMoment] = Field(description=\"\"\"A list of musical moments in a Vaudeville play, as MusicalMoment objects. Many of these musical moments reuse some preexisting (and often well-known)  melody or tune.  These are variously called \"melodie”, or “air”, and identified with a short title that refers in some way to an opera or collection of melodies from which it was drawn.  The titles might include the names of works, or other characters in those original works. In the context of the plays, these tunes become the vehicle for newly composed lyrics, which are normally rhymed, and which normally follow the poetic scansion and structure of the original lyrics.  Rhyme, versification and structure are thus of interest to us.\"\"\")    \n",
    "\n",
    "structured_llm = llm.with_structured_output(VaudevillePlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ccfdc",
   "metadata": {},
   "source": [
    "This is our system prompt. It's always a good technique to tell it that it's an *expert* in your field. It seems strange, but it does help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f903d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a literary analyst specializing in French Vaudeville plays from the 18th century. \n",
    "Your goal is to identify each musical moment in the text, and for each, extract detailed structured information, \n",
    "including act, scene, characters, dramatic situation, air or melodie, poetic text, rhyme scheme, poetic form, end-of-line accents, syllable count, and any irregularities. \n",
    "Some parts of the text were slightly misinterpreted by the file reader (e.g., missing spaces or strange line breaks).\n",
    "\"\"\"\n",
    "human_prompt = \"\"\"\n",
    "Given the following chunk of the play, analyze and return the musical moments as a structured VaudevillePlay object.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74678fd",
   "metadata": {},
   "source": [
    "Here, we set up a basic LangGraph sequence. This specific version of the app uses indexes to go the list of scenes, and is thus called with a for loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "31937dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import List, TypedDict, Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",system_prompt),\n",
    "    (\"human\",\"Context:\\n{context}\\n\\nQuestion:\\n{question}\")\n",
    "     ])\n",
    "\n",
    "class State(TypedDict):\n",
    "    index: int\n",
    "    context: Document\n",
    "    answer: str\n",
    "\n",
    "def check_index(state: State):\n",
    "    return state\n",
    "\n",
    "def retrieve_doc(state: State):\n",
    "    document = all_splits[state[\"index\"]]\n",
    "    return {\"context\": document}\n",
    "\n",
    "def generate(state: State):\n",
    "    i = state[\"index\"]\n",
    "    message = prompt.invoke({\"question\":human_prompt,\"context\" : f'Act {all_indexes.all_scenes[i].act}, Scene {all_indexes.all_scenes[i].scene}:\\n\\n {state[\"context\"].page_content}'})\n",
    "    response = structured_llm.invoke(message)\n",
    "    return {\"answer\": response}\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([check_index, retrieve_doc, generate])\n",
    "graph_builder.add_edge(START, \"check_index\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafbe57e",
   "metadata": {},
   "source": [
    "### Analyzing the scenes and merging them together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6552d3d8",
   "metadata": {},
   "source": [
    "This is the new code. It goes through each scene, calls the LangGraph, then merges all of the scenes together into one object. Then, it exports it as a csv (based on the filename of the PDF) to a csv_outputs folder in your directory. In the github repository, you can view the 7 objects I tested. Or, you can follow this [link](https://docs.google.com/spreadsheets/d/1WBVLnW_EfVwT60LsOVykd4lNaYEB0NAPvJUaMvyyBrM/edit?usp=sharing) to see the spreadsheet on Google Sheets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1d924c",
   "metadata": {},
   "source": [
    "You might have to add a folder `csv_outputs` to your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e9fa8fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_scenes(docs: List[Document]) -> List[MusicalMoment]:\n",
    "    all_moments: List[MusicalMoment] = []\n",
    "\n",
    "    for i,doc in enumerate(docs):\n",
    "        response = graph.invoke({\"index\": i})\n",
    "        moments = response[\"answer\"].musicalMoments\n",
    "        all_moments.extend(moments)\n",
    "    \n",
    "    return all_moments\n",
    "\n",
    "all_moments = analyze_scenes(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf0e4d",
   "metadata": {},
   "source": [
    "Finally, we dump the results into a dictionary, then export that as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5d26f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Convert all MusicalMoment objects to dicts\n",
    "moments_dicts = [moment.model_dump() for moment in all_moments]\n",
    "\n",
    "# Get all field names from the first moment\n",
    "fieldnames = moments_dicts[0].keys() if moments_dicts else []\n",
    "\n",
    "# Write to CSV\n",
    "# Ensure the output folder exists\n",
    "output_folder = \"csv_outputs\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Build the output path\n",
    "output_path = os.path.join(output_folder, os.path.basename(csv_filename))\n",
    "\n",
    "with open(output_path, \"w\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in moments_dicts:\n",
    "        # Convert lists to strings for CSV output\n",
    "        for key, value in row.items():\n",
    "            if isinstance(value, list):\n",
    "                row[key] = \"; \".join(str(v) for v in value)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25104268",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This system is highly effective, and serves as a solid template for a Structured Output App. \n",
    "\n",
    "However, some improvements are needed for this to reach its most accurate form. Most notably, the descriptions for the variable within the Pydantic schema are lacking expertise in the subject. To reach it's most effective form, an expert in these plays would have to write these descriptions.\n",
    "\n",
    "That being said, this system is impressive as is. Reading through all 7 Vaudeville plays (~50 pages each) only took about 20 minutes of passive runtime and a few dollars with the OpenAI API. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
